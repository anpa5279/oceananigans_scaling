#!/bin/bash

jobn=perform4_648-3
nodes=1
cpus=64
gpus=4
ntasks=$((nodes*gpus))
rm -rf outputs/$jobn
mkdir outputs/$jobn

cp oceananigans.jl outputs/$jobn/
cp stokes.jl outputs/$jobn/
echo '---> Directory Made'

cd outputs/$jobn/

cat > EXEC_STEP << EXEC
#!/bin/sh

#PBS -A UCUB0166 
#PBS -N $jobn
#PBS -q main
#PBS -j oe
#PBS -l job_priority=economy
#PBS -l walltime=03:30:00
#PBS -l select=$nodes:ncpus=$cpus:mpiprocs=$gpus:ngpus=$gpus
#PBS -l gpu_type=a100
# Use moar processes for precompilation to speed things up
export JULIA_NUM_PRECOMPILE_TASKS=$cpus
export JULIA_NUM_THREADS=$cpus

# Load critical modules
module --force purge
module load ncarenv/23.09 nvhpc/24.7 cuda/12.2.1 cray-mpich/8.1.29

module list

# Utter mystical incantations to perform various miracles
export MPICH_GPU_SUPPORT_ENABLED=1
export MPICH_GPU_MANAGED_MEMORY_SUPPORT_ENABLED=1
export JULIA_MPI_HAS_CUDA=true
export PALS_TRANSFER=false
export JULIA_CUDA_MEMORY_POOL=none

julia --project -e 'using Pkg; Pkg.instantiate()'
# Tell MPI that we would like to use the system binary we loaded with module load cray-mpich
julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary(vendor="cray", force=true)'
# Only need to run if you want to reset or update things (did you update the amount of  nodes and processors?)
julia --project -e 'using MPI; using CUDA; CUDA.precompile_runtime()'
# 2. Update packages to the environment that we need to use. not always necessary
julia --project -e 'using Pkg; Pkg.add("MPI"); Pkg.add("MPIPreferences"); Pkg.add("CUDA"); Pkg.add("Oceananigans"); Pkg.add("Printf")'
# Finally, let's run this thing
mpiexec -n $ntasks -ppn $gpus set_gpu_rank julia --project oceananigans.jl
EXEC

qsub < EXEC_STEP